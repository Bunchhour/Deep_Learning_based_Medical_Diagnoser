{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2113b5f1",
   "metadata": {},
   "source": [
    "# 1. Understand the Project Structure\n",
    "The original project uses symptom descriptions (text) → LSTM → disease prediction.\n",
    "\n",
    "Since you want to start with a standard neural network, we CANNOT feed raw text directly.\n",
    "Instead, we convert text into numerical features using something like:\n",
    "\n",
    "- Bag-of-Words (BoW)\n",
    "\n",
    "- TF-IDF\n",
    "\n",
    "- Word embeddings averaged (optional)\n",
    "\n",
    "For beginners, TF-IDF is the easiest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a995ba",
   "metadata": {},
   "source": [
    "# Step 2 - Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "52925bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.10.19 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 16:41:31) [MSC v.1929 64 bit (AMD64)]\n",
      "Python executable: d:\\2024\\anaconda\\envs\\cuda_env\\python.exe\n",
      "NumPy version: 1.26.4\n",
      "NumPy location: d:\\2024\\anaconda\\envs\\cuda_env\\lib\\site-packages\\numpy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Verify NumPy installation and import\n",
    "import sys\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"NumPy version: {np.__version__}\")\n",
    "    print(f\"NumPy location: {np.__file__}\")\n",
    "except Exception as e:\n",
    "    print(f\"NumPy import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "afcea6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"../Dataset/medical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b4403641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Patient_Problem",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Disease",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Prescription",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "46e599c3-e1c3-46ef-a0cc-4ffe96f581e7",
       "rows": [
        [
         "0",
         "Constant fatigue and muscle weakness, struggling to stay awake.",
         "Chronic Fatigue Syndrome",
         "Cognitive behavioral therapy, graded exercise therapy."
        ],
        [
         "1",
         "Frequent severe migraines, sensitivity to light and sound.",
         "Migraine with Aura",
         "Prescription triptans, avoid triggers like bright lights."
        ],
        [
         "2",
         "Sudden weight gain and feeling cold, especially in the hands and feet.",
         "Hypothyroidism",
         "Levothyroxine to regulate thyroid hormone levels."
        ],
        [
         "3",
         "High fever, sore throat, and swollen lymph nodes, feeling very weak.",
         "Mononucleosis",
         "Rest and hydration, ibuprofen for pain."
        ],
        [
         "4",
         "Excessive thirst and frequent urination, dry mouth persistently.",
         "Diabetes Mellitus",
         "Insulin therapy and lifestyle changes."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Problem</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Prescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Constant fatigue and muscle weakness, struggli...</td>\n",
       "      <td>Chronic Fatigue Syndrome</td>\n",
       "      <td>Cognitive behavioral therapy, graded exercise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frequent severe migraines, sensitivity to ligh...</td>\n",
       "      <td>Migraine with Aura</td>\n",
       "      <td>Prescription triptans, avoid triggers like bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sudden weight gain and feeling cold, especiall...</td>\n",
       "      <td>Hypothyroidism</td>\n",
       "      <td>Levothyroxine to regulate thyroid hormone levels.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fever, sore throat, and swollen lymph nod...</td>\n",
       "      <td>Mononucleosis</td>\n",
       "      <td>Rest and hydration, ibuprofen for pain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Excessive thirst and frequent urination, dry m...</td>\n",
       "      <td>Diabetes Mellitus</td>\n",
       "      <td>Insulin therapy and lifestyle changes.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Patient_Problem  \\\n",
       "0  Constant fatigue and muscle weakness, struggli...   \n",
       "1  Frequent severe migraines, sensitivity to ligh...   \n",
       "2  Sudden weight gain and feeling cold, especiall...   \n",
       "3  High fever, sore throat, and swollen lymph nod...   \n",
       "4  Excessive thirst and frequent urination, dry m...   \n",
       "\n",
       "                    Disease                                       Prescription  \n",
       "0  Chronic Fatigue Syndrome  Cognitive behavioral therapy, graded exercise ...  \n",
       "1        Migraine with Aura  Prescription triptans, avoid triggers like bri...  \n",
       "2            Hypothyroidism  Levothyroxine to regulate thyroid hormone levels.  \n",
       "3             Mononucleosis            Rest and hydration, ibuprofen for pain.  \n",
       "4         Diabetes Mellitus             Insulin therapy and lifestyle changes.  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ed30680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Patient_Problem",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Disease",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Prescription",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a237ec06-5e91-494a-837d-d4b816b7fa4c",
       "rows": [
        [
         "402",
         "Noticeable thinning of the hair on the top of the head.",
         "Androgenetic Alopecia",
         "Minoxidil, finasteride for males."
        ],
        [
         "403",
         "Greenish discharge from the eyes, accompanied by itching and irritation.",
         "Conjunctivitis",
         "Antibiotic or antihistamine eye drops."
        ],
        [
         "404",
         "Experiencing confusion, difficulty speaking, and understanding speech.",
         "Stroke",
         "Immediate medical attention, clot-busting drugs."
        ],
        [
         "405",
         "Constant feeling of fullness in the ears and hearing loss.",
         "Eustachian Tube Dysfunction",
         "Nasal steroids, autoinflation exercises."
        ],
        [
         "406",
         "Blood in stool, along with a change in bowel movement frequency.",
         "Colorectal Cancer",
         "Colonoscopy, potentially surgery, chemotherapy."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_Problem</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Prescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>Noticeable thinning of the hair on the top of ...</td>\n",
       "      <td>Androgenetic Alopecia</td>\n",
       "      <td>Minoxidil, finasteride for males.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Greenish discharge from the eyes, accompanied ...</td>\n",
       "      <td>Conjunctivitis</td>\n",
       "      <td>Antibiotic or antihistamine eye drops.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Experiencing confusion, difficulty speaking, a...</td>\n",
       "      <td>Stroke</td>\n",
       "      <td>Immediate medical attention, clot-busting drugs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>Constant feeling of fullness in the ears and h...</td>\n",
       "      <td>Eustachian Tube Dysfunction</td>\n",
       "      <td>Nasal steroids, autoinflation exercises.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Blood in stool, along with a change in bowel m...</td>\n",
       "      <td>Colorectal Cancer</td>\n",
       "      <td>Colonoscopy, potentially surgery, chemotherapy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Patient_Problem  \\\n",
       "402  Noticeable thinning of the hair on the top of ...   \n",
       "403  Greenish discharge from the eyes, accompanied ...   \n",
       "404  Experiencing confusion, difficulty speaking, a...   \n",
       "405  Constant feeling of fullness in the ears and h...   \n",
       "406  Blood in stool, along with a change in bowel m...   \n",
       "\n",
       "                         Disease  \\\n",
       "402        Androgenetic Alopecia   \n",
       "403               Conjunctivitis   \n",
       "404                       Stroke   \n",
       "405  Eustachian Tube Dysfunction   \n",
       "406            Colorectal Cancer   \n",
       "\n",
       "                                         Prescription  \n",
       "402                 Minoxidil, finasteride for males.  \n",
       "403            Antibiotic or antihistamine eye drops.  \n",
       "404  Immediate medical attention, clot-busting drugs.  \n",
       "405          Nasal steroids, autoinflation exercises.  \n",
       "406   Colonoscopy, potentially surgery, chemotherapy.  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "07860af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Constant fatigue and muscle weakness, struggli...\n",
      "1    Frequent severe migraines, sensitivity to ligh...\n",
      "2    Sudden weight gain and feeling cold, especiall...\n",
      "3    High fever, sore throat, and swollen lymph nod...\n",
      "4    Excessive thirst and frequent urination, dry m...\n",
      "Name: Patient_Problem, dtype: object\n",
      "------------\n",
      "0    Chronic Fatigue Syndrome\n",
      "1          Migraine with Aura\n",
      "2              Hypothyroidism\n",
      "3               Mononucleosis\n",
      "4           Diabetes Mellitus\n",
      "Name: Disease, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Combine Patient_Problem and Prescription into one text field\n",
    "texts = dataset['Patient_Problem']\n",
    "labels = dataset['Disease']\n",
    "print(texts.head())\n",
    "print(\"------------\")\n",
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ca59041",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberofclass = labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "32bcdd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "print(numberofclass.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881dab7",
   "metadata": {},
   "source": [
    "# Step 3 - Convert text -> Nummerical vectors (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d37424c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert text to TF-IDF vectors\n",
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X = vectorizer.fit_transform(texts).toarray()\n",
    "\n",
    "# Encode disease labels into numbers\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c70de4",
   "metadata": {},
   "source": [
    "# Step 4 - Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af07580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to pytorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "417246cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f3c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c179fbe4",
   "metadata": {},
   "source": [
    "# Step 5 - Build a standard neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "26a104e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module): # MLP = multilayer perceptron\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MLP,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30ec0e7",
   "metadata": {},
   "source": [
    "**Initialize the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc0adfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "num_classes = len(encoder.classes_)\n",
    "model = MLP(input_dim, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "caeecf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "178\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=616, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=178, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(input_dim)\n",
    "print(num_classes)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27675493",
   "metadata": {},
   "source": [
    "# Step 6 - Loss Function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "61e8d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteration = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b29d15",
   "metadata": {},
   "source": [
    "# Step 7 - Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac5d5e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/1000], Loss: 0.0043\n",
      "Epoch [4/1000], Loss: 0.0043\n",
      "Epoch [6/1000], Loss: 0.0043\n",
      "Epoch [8/1000], Loss: 0.0043\n",
      "Epoch [10/1000], Loss: 0.0043\n",
      "Epoch [12/1000], Loss: 0.0043\n",
      "Epoch [14/1000], Loss: 0.0043\n",
      "Epoch [16/1000], Loss: 0.0043\n",
      "Epoch [18/1000], Loss: 0.0043\n",
      "Epoch [20/1000], Loss: 0.0043\n",
      "Epoch [22/1000], Loss: 0.0043\n",
      "Epoch [24/1000], Loss: 0.0043\n",
      "Epoch [26/1000], Loss: 0.0043\n",
      "Epoch [28/1000], Loss: 0.0043\n",
      "Epoch [30/1000], Loss: 0.0043\n",
      "Epoch [32/1000], Loss: 0.0043\n",
      "Epoch [34/1000], Loss: 0.0043\n",
      "Epoch [36/1000], Loss: 0.0043\n",
      "Epoch [38/1000], Loss: 0.0043\n",
      "Epoch [40/1000], Loss: 0.0043\n",
      "Epoch [42/1000], Loss: 0.0043\n",
      "Epoch [44/1000], Loss: 0.0043\n",
      "Epoch [46/1000], Loss: 0.0043\n",
      "Epoch [48/1000], Loss: 0.0043\n",
      "Epoch [50/1000], Loss: 0.0043\n",
      "Epoch [52/1000], Loss: 0.0043\n",
      "Epoch [54/1000], Loss: 0.0043\n",
      "Epoch [56/1000], Loss: 0.0043\n",
      "Epoch [58/1000], Loss: 0.0043\n",
      "Epoch [60/1000], Loss: 0.0043\n",
      "Epoch [62/1000], Loss: 0.0043\n",
      "Epoch [64/1000], Loss: 0.0043\n",
      "Epoch [38/1000], Loss: 0.0043\n",
      "Epoch [40/1000], Loss: 0.0043\n",
      "Epoch [42/1000], Loss: 0.0043\n",
      "Epoch [44/1000], Loss: 0.0043\n",
      "Epoch [46/1000], Loss: 0.0043\n",
      "Epoch [48/1000], Loss: 0.0043\n",
      "Epoch [50/1000], Loss: 0.0043\n",
      "Epoch [52/1000], Loss: 0.0043\n",
      "Epoch [54/1000], Loss: 0.0043\n",
      "Epoch [56/1000], Loss: 0.0043\n",
      "Epoch [58/1000], Loss: 0.0043\n",
      "Epoch [60/1000], Loss: 0.0043\n",
      "Epoch [62/1000], Loss: 0.0043\n",
      "Epoch [64/1000], Loss: 0.0043\n",
      "Epoch [66/1000], Loss: 0.0043\n",
      "Epoch [68/1000], Loss: 0.0043\n",
      "Epoch [70/1000], Loss: 0.0043\n",
      "Epoch [72/1000], Loss: 0.0043\n",
      "Epoch [74/1000], Loss: 0.0043\n",
      "Epoch [76/1000], Loss: 0.0043\n",
      "Epoch [78/1000], Loss: 0.0043\n",
      "Epoch [80/1000], Loss: 0.0043\n",
      "Epoch [82/1000], Loss: 0.0043\n",
      "Epoch [84/1000], Loss: 0.0043\n",
      "Epoch [86/1000], Loss: 0.0043\n",
      "Epoch [88/1000], Loss: 0.0043\n",
      "Epoch [90/1000], Loss: 0.0043\n",
      "Epoch [92/1000], Loss: 0.0043\n",
      "Epoch [94/1000], Loss: 0.0043\n",
      "Epoch [96/1000], Loss: 0.0043\n",
      "Epoch [98/1000], Loss: 0.0043\n",
      "Epoch [66/1000], Loss: 0.0043\n",
      "Epoch [68/1000], Loss: 0.0043\n",
      "Epoch [70/1000], Loss: 0.0043\n",
      "Epoch [72/1000], Loss: 0.0043\n",
      "Epoch [74/1000], Loss: 0.0043\n",
      "Epoch [76/1000], Loss: 0.0043\n",
      "Epoch [78/1000], Loss: 0.0043\n",
      "Epoch [80/1000], Loss: 0.0043\n",
      "Epoch [82/1000], Loss: 0.0043\n",
      "Epoch [84/1000], Loss: 0.0043\n",
      "Epoch [86/1000], Loss: 0.0043\n",
      "Epoch [88/1000], Loss: 0.0043\n",
      "Epoch [90/1000], Loss: 0.0043\n",
      "Epoch [92/1000], Loss: 0.0043\n",
      "Epoch [94/1000], Loss: 0.0043\n",
      "Epoch [96/1000], Loss: 0.0043\n",
      "Epoch [98/1000], Loss: 0.0043\n",
      "Epoch [100/1000], Loss: 0.0043\n",
      "Epoch [102/1000], Loss: 0.0043\n",
      "Epoch [104/1000], Loss: 0.0043\n",
      "Epoch [106/1000], Loss: 0.0043\n",
      "Epoch [108/1000], Loss: 0.0043\n",
      "Epoch [110/1000], Loss: 0.0043\n",
      "Epoch [112/1000], Loss: 0.0043\n",
      "Epoch [114/1000], Loss: 0.0043\n",
      "Epoch [116/1000], Loss: 0.0043\n",
      "Epoch [118/1000], Loss: 0.0043\n",
      "Epoch [120/1000], Loss: 0.0043\n",
      "Epoch [122/1000], Loss: 0.0043\n",
      "Epoch [124/1000], Loss: 0.0043\n",
      "Epoch [126/1000], Loss: 0.0043\n",
      "Epoch [128/1000], Loss: 0.0043\n",
      "Epoch [130/1000], Loss: 0.0043\n",
      "Epoch [100/1000], Loss: 0.0043\n",
      "Epoch [102/1000], Loss: 0.0043\n",
      "Epoch [104/1000], Loss: 0.0043\n",
      "Epoch [106/1000], Loss: 0.0043\n",
      "Epoch [108/1000], Loss: 0.0043\n",
      "Epoch [110/1000], Loss: 0.0043\n",
      "Epoch [112/1000], Loss: 0.0043\n",
      "Epoch [114/1000], Loss: 0.0043\n",
      "Epoch [116/1000], Loss: 0.0043\n",
      "Epoch [118/1000], Loss: 0.0043\n",
      "Epoch [120/1000], Loss: 0.0043\n",
      "Epoch [122/1000], Loss: 0.0043\n",
      "Epoch [124/1000], Loss: 0.0043\n",
      "Epoch [126/1000], Loss: 0.0043\n",
      "Epoch [128/1000], Loss: 0.0043\n",
      "Epoch [130/1000], Loss: 0.0043\n",
      "Epoch [132/1000], Loss: 0.0043\n",
      "Epoch [134/1000], Loss: 0.0043\n",
      "Epoch [136/1000], Loss: 0.0043\n",
      "Epoch [138/1000], Loss: 0.0043\n",
      "Epoch [140/1000], Loss: 0.0043\n",
      "Epoch [142/1000], Loss: 0.0043\n",
      "Epoch [144/1000], Loss: 0.0043\n",
      "Epoch [146/1000], Loss: 0.0043\n",
      "Epoch [148/1000], Loss: 0.0043\n",
      "Epoch [150/1000], Loss: 0.0043\n",
      "Epoch [152/1000], Loss: 0.0043\n",
      "Epoch [154/1000], Loss: 0.0043\n",
      "Epoch [156/1000], Loss: 0.0043\n",
      "Epoch [158/1000], Loss: 0.0043\n",
      "Epoch [160/1000], Loss: 0.0043\n",
      "Epoch [162/1000], Loss: 0.0043\n",
      "Epoch [132/1000], Loss: 0.0043\n",
      "Epoch [134/1000], Loss: 0.0043\n",
      "Epoch [136/1000], Loss: 0.0043\n",
      "Epoch [138/1000], Loss: 0.0043\n",
      "Epoch [140/1000], Loss: 0.0043\n",
      "Epoch [142/1000], Loss: 0.0043\n",
      "Epoch [144/1000], Loss: 0.0043\n",
      "Epoch [146/1000], Loss: 0.0043\n",
      "Epoch [148/1000], Loss: 0.0043\n",
      "Epoch [150/1000], Loss: 0.0043\n",
      "Epoch [152/1000], Loss: 0.0043\n",
      "Epoch [154/1000], Loss: 0.0043\n",
      "Epoch [156/1000], Loss: 0.0043\n",
      "Epoch [158/1000], Loss: 0.0043\n",
      "Epoch [160/1000], Loss: 0.0043\n",
      "Epoch [162/1000], Loss: 0.0043\n",
      "Epoch [164/1000], Loss: 0.0043\n",
      "Epoch [166/1000], Loss: 0.0043\n",
      "Epoch [168/1000], Loss: 0.0043\n",
      "Epoch [170/1000], Loss: 0.0043\n",
      "Epoch [172/1000], Loss: 0.0043\n",
      "Epoch [174/1000], Loss: 0.0043\n",
      "Epoch [176/1000], Loss: 0.0043\n",
      "Epoch [178/1000], Loss: 0.0043\n",
      "Epoch [180/1000], Loss: 0.0043\n",
      "Epoch [182/1000], Loss: 0.0043\n",
      "Epoch [184/1000], Loss: 0.0043\n",
      "Epoch [186/1000], Loss: 0.0043\n",
      "Epoch [188/1000], Loss: 0.0043\n",
      "Epoch [190/1000], Loss: 0.0043\n",
      "Epoch [192/1000], Loss: 0.0043\n",
      "Epoch [194/1000], Loss: 0.0043\n",
      "Epoch [164/1000], Loss: 0.0043\n",
      "Epoch [166/1000], Loss: 0.0043\n",
      "Epoch [168/1000], Loss: 0.0043\n",
      "Epoch [170/1000], Loss: 0.0043\n",
      "Epoch [172/1000], Loss: 0.0043\n",
      "Epoch [174/1000], Loss: 0.0043\n",
      "Epoch [176/1000], Loss: 0.0043\n",
      "Epoch [178/1000], Loss: 0.0043\n",
      "Epoch [180/1000], Loss: 0.0043\n",
      "Epoch [182/1000], Loss: 0.0043\n",
      "Epoch [184/1000], Loss: 0.0043\n",
      "Epoch [186/1000], Loss: 0.0043\n",
      "Epoch [188/1000], Loss: 0.0043\n",
      "Epoch [190/1000], Loss: 0.0043\n",
      "Epoch [192/1000], Loss: 0.0043\n",
      "Epoch [194/1000], Loss: 0.0043\n",
      "Epoch [196/1000], Loss: 0.0043\n",
      "Epoch [198/1000], Loss: 0.0043\n",
      "Epoch [200/1000], Loss: 0.0043\n",
      "Epoch [202/1000], Loss: 0.0043\n",
      "Epoch [204/1000], Loss: 0.0043\n",
      "Epoch [206/1000], Loss: 0.0043\n",
      "Epoch [208/1000], Loss: 0.0043\n",
      "Epoch [210/1000], Loss: 0.0043\n",
      "Epoch [212/1000], Loss: 0.0043\n",
      "Epoch [214/1000], Loss: 0.0043\n",
      "Epoch [216/1000], Loss: 0.0043\n",
      "Epoch [218/1000], Loss: 0.0043\n",
      "Epoch [220/1000], Loss: 0.0043\n",
      "Epoch [222/1000], Loss: 0.0043\n",
      "Epoch [224/1000], Loss: 0.0043\n",
      "Epoch [226/1000], Loss: 0.0043\n",
      "Epoch [196/1000], Loss: 0.0043\n",
      "Epoch [198/1000], Loss: 0.0043\n",
      "Epoch [200/1000], Loss: 0.0043\n",
      "Epoch [202/1000], Loss: 0.0043\n",
      "Epoch [204/1000], Loss: 0.0043\n",
      "Epoch [206/1000], Loss: 0.0043\n",
      "Epoch [208/1000], Loss: 0.0043\n",
      "Epoch [210/1000], Loss: 0.0043\n",
      "Epoch [212/1000], Loss: 0.0043\n",
      "Epoch [214/1000], Loss: 0.0043\n",
      "Epoch [216/1000], Loss: 0.0043\n",
      "Epoch [218/1000], Loss: 0.0043\n",
      "Epoch [220/1000], Loss: 0.0043\n",
      "Epoch [222/1000], Loss: 0.0043\n",
      "Epoch [224/1000], Loss: 0.0043\n",
      "Epoch [226/1000], Loss: 0.0043\n",
      "Epoch [228/1000], Loss: 0.0043\n",
      "Epoch [230/1000], Loss: 0.0043\n",
      "Epoch [232/1000], Loss: 0.0043\n",
      "Epoch [234/1000], Loss: 0.0043\n",
      "Epoch [236/1000], Loss: 0.0043\n",
      "Epoch [238/1000], Loss: 0.0043\n",
      "Epoch [240/1000], Loss: 0.0043\n",
      "Epoch [242/1000], Loss: 0.0043\n",
      "Epoch [244/1000], Loss: 0.0043\n",
      "Epoch [246/1000], Loss: 0.0043\n",
      "Epoch [248/1000], Loss: 0.0043\n",
      "Epoch [250/1000], Loss: 0.0043\n",
      "Epoch [252/1000], Loss: 0.0043\n",
      "Epoch [254/1000], Loss: 0.0043\n",
      "Epoch [256/1000], Loss: 0.0043\n",
      "Epoch [258/1000], Loss: 0.0043\n",
      "Epoch [228/1000], Loss: 0.0043\n",
      "Epoch [230/1000], Loss: 0.0043\n",
      "Epoch [232/1000], Loss: 0.0043\n",
      "Epoch [234/1000], Loss: 0.0043\n",
      "Epoch [236/1000], Loss: 0.0043\n",
      "Epoch [238/1000], Loss: 0.0043\n",
      "Epoch [240/1000], Loss: 0.0043\n",
      "Epoch [242/1000], Loss: 0.0043\n",
      "Epoch [244/1000], Loss: 0.0043\n",
      "Epoch [246/1000], Loss: 0.0043\n",
      "Epoch [248/1000], Loss: 0.0043\n",
      "Epoch [250/1000], Loss: 0.0043\n",
      "Epoch [252/1000], Loss: 0.0043\n",
      "Epoch [254/1000], Loss: 0.0043\n",
      "Epoch [256/1000], Loss: 0.0043\n",
      "Epoch [258/1000], Loss: 0.0043\n",
      "Epoch [260/1000], Loss: 0.0043\n",
      "Epoch [262/1000], Loss: 0.0043\n",
      "Epoch [264/1000], Loss: 0.0043\n",
      "Epoch [266/1000], Loss: 0.0043\n",
      "Epoch [268/1000], Loss: 0.0043\n",
      "Epoch [270/1000], Loss: 0.0043\n",
      "Epoch [272/1000], Loss: 0.0043\n",
      "Epoch [274/1000], Loss: 0.0043\n",
      "Epoch [276/1000], Loss: 0.0043\n",
      "Epoch [278/1000], Loss: 0.0043\n",
      "Epoch [280/1000], Loss: 0.0043\n",
      "Epoch [282/1000], Loss: 0.0043\n",
      "Epoch [284/1000], Loss: 0.0043\n",
      "Epoch [286/1000], Loss: 0.0043\n",
      "Epoch [288/1000], Loss: 0.0043\n",
      "Epoch [290/1000], Loss: 0.0043\n",
      "Epoch [292/1000], Loss: 0.0043\n",
      "Epoch [260/1000], Loss: 0.0043\n",
      "Epoch [262/1000], Loss: 0.0043\n",
      "Epoch [264/1000], Loss: 0.0043\n",
      "Epoch [266/1000], Loss: 0.0043\n",
      "Epoch [268/1000], Loss: 0.0043\n",
      "Epoch [270/1000], Loss: 0.0043\n",
      "Epoch [272/1000], Loss: 0.0043\n",
      "Epoch [274/1000], Loss: 0.0043\n",
      "Epoch [276/1000], Loss: 0.0043\n",
      "Epoch [278/1000], Loss: 0.0043\n",
      "Epoch [280/1000], Loss: 0.0043\n",
      "Epoch [282/1000], Loss: 0.0043\n",
      "Epoch [284/1000], Loss: 0.0043\n",
      "Epoch [286/1000], Loss: 0.0043\n",
      "Epoch [288/1000], Loss: 0.0043\n",
      "Epoch [290/1000], Loss: 0.0043\n",
      "Epoch [292/1000], Loss: 0.0043\n",
      "Epoch [294/1000], Loss: 0.0043\n",
      "Epoch [296/1000], Loss: 0.0043\n",
      "Epoch [298/1000], Loss: 0.0043\n",
      "Epoch [300/1000], Loss: 0.0043\n",
      "Epoch [302/1000], Loss: 0.0043\n",
      "Epoch [304/1000], Loss: 0.0043\n",
      "Epoch [306/1000], Loss: 0.0043\n",
      "Epoch [308/1000], Loss: 0.0043\n",
      "Epoch [310/1000], Loss: 0.0043\n",
      "Epoch [312/1000], Loss: 0.0043\n",
      "Epoch [314/1000], Loss: 0.0043\n",
      "Epoch [316/1000], Loss: 0.0043\n",
      "Epoch [318/1000], Loss: 0.0043\n",
      "Epoch [320/1000], Loss: 0.0043\n",
      "Epoch [322/1000], Loss: 0.0043\n",
      "Epoch [324/1000], Loss: 0.0043\n",
      "Epoch [326/1000], Loss: 0.0043\n",
      "Epoch [328/1000], Loss: 0.0043\n",
      "Epoch [294/1000], Loss: 0.0043\n",
      "Epoch [296/1000], Loss: 0.0043\n",
      "Epoch [298/1000], Loss: 0.0043\n",
      "Epoch [300/1000], Loss: 0.0043\n",
      "Epoch [302/1000], Loss: 0.0043\n",
      "Epoch [304/1000], Loss: 0.0043\n",
      "Epoch [306/1000], Loss: 0.0043\n",
      "Epoch [308/1000], Loss: 0.0043\n",
      "Epoch [310/1000], Loss: 0.0043\n",
      "Epoch [312/1000], Loss: 0.0043\n",
      "Epoch [314/1000], Loss: 0.0043\n",
      "Epoch [316/1000], Loss: 0.0043\n",
      "Epoch [318/1000], Loss: 0.0043\n",
      "Epoch [320/1000], Loss: 0.0043\n",
      "Epoch [322/1000], Loss: 0.0043\n",
      "Epoch [324/1000], Loss: 0.0043\n",
      "Epoch [326/1000], Loss: 0.0043\n",
      "Epoch [328/1000], Loss: 0.0043\n",
      "Epoch [330/1000], Loss: 0.0043\n",
      "Epoch [332/1000], Loss: 0.0043\n",
      "Epoch [334/1000], Loss: 0.0043\n",
      "Epoch [336/1000], Loss: 0.0043\n",
      "Epoch [338/1000], Loss: 0.0043\n",
      "Epoch [340/1000], Loss: 0.0043\n",
      "Epoch [342/1000], Loss: 0.0043\n",
      "Epoch [344/1000], Loss: 0.0043\n",
      "Epoch [346/1000], Loss: 0.0043\n",
      "Epoch [348/1000], Loss: 0.0043\n",
      "Epoch [350/1000], Loss: 0.0043\n",
      "Epoch [352/1000], Loss: 0.0043\n",
      "Epoch [354/1000], Loss: 0.0043\n",
      "Epoch [356/1000], Loss: 0.0043\n",
      "Epoch [358/1000], Loss: 0.0043\n",
      "Epoch [360/1000], Loss: 0.0043\n",
      "Epoch [362/1000], Loss: 0.0043\n",
      "Epoch [364/1000], Loss: 0.0043\n",
      "Epoch [366/1000], Loss: 0.0043\n",
      "Epoch [330/1000], Loss: 0.0043\n",
      "Epoch [332/1000], Loss: 0.0043\n",
      "Epoch [334/1000], Loss: 0.0043\n",
      "Epoch [336/1000], Loss: 0.0043\n",
      "Epoch [338/1000], Loss: 0.0043\n",
      "Epoch [340/1000], Loss: 0.0043\n",
      "Epoch [342/1000], Loss: 0.0043\n",
      "Epoch [344/1000], Loss: 0.0043\n",
      "Epoch [346/1000], Loss: 0.0043\n",
      "Epoch [348/1000], Loss: 0.0043\n",
      "Epoch [350/1000], Loss: 0.0043\n",
      "Epoch [352/1000], Loss: 0.0043\n",
      "Epoch [354/1000], Loss: 0.0043\n",
      "Epoch [356/1000], Loss: 0.0043\n",
      "Epoch [358/1000], Loss: 0.0043\n",
      "Epoch [360/1000], Loss: 0.0043\n",
      "Epoch [362/1000], Loss: 0.0043\n",
      "Epoch [364/1000], Loss: 0.0043\n",
      "Epoch [366/1000], Loss: 0.0043\n",
      "Epoch [368/1000], Loss: 0.0043\n",
      "Epoch [370/1000], Loss: 0.0043\n",
      "Epoch [372/1000], Loss: 0.0043\n",
      "Epoch [374/1000], Loss: 0.0043\n",
      "Epoch [376/1000], Loss: 0.0043\n",
      "Epoch [378/1000], Loss: 0.0043\n",
      "Epoch [380/1000], Loss: 0.0043\n",
      "Epoch [382/1000], Loss: 0.0043\n",
      "Epoch [384/1000], Loss: 0.0043\n",
      "Epoch [386/1000], Loss: 0.0043\n",
      "Epoch [388/1000], Loss: 0.0043\n",
      "Epoch [390/1000], Loss: 0.0043\n",
      "Epoch [392/1000], Loss: 0.0043\n",
      "Epoch [394/1000], Loss: 0.0043\n",
      "Epoch [396/1000], Loss: 0.0043\n",
      "Epoch [398/1000], Loss: 0.0043\n",
      "Epoch [400/1000], Loss: 0.0043\n",
      "Epoch [402/1000], Loss: 0.0043\n",
      "Epoch [368/1000], Loss: 0.0043\n",
      "Epoch [370/1000], Loss: 0.0043\n",
      "Epoch [372/1000], Loss: 0.0043\n",
      "Epoch [374/1000], Loss: 0.0043\n",
      "Epoch [376/1000], Loss: 0.0043\n",
      "Epoch [378/1000], Loss: 0.0043\n",
      "Epoch [380/1000], Loss: 0.0043\n",
      "Epoch [382/1000], Loss: 0.0043\n",
      "Epoch [384/1000], Loss: 0.0043\n",
      "Epoch [386/1000], Loss: 0.0043\n",
      "Epoch [388/1000], Loss: 0.0043\n",
      "Epoch [390/1000], Loss: 0.0043\n",
      "Epoch [392/1000], Loss: 0.0043\n",
      "Epoch [394/1000], Loss: 0.0043\n",
      "Epoch [396/1000], Loss: 0.0043\n",
      "Epoch [398/1000], Loss: 0.0043\n",
      "Epoch [400/1000], Loss: 0.0043\n",
      "Epoch [402/1000], Loss: 0.0043\n",
      "Epoch [404/1000], Loss: 0.0043\n",
      "Epoch [406/1000], Loss: 0.0043\n",
      "Epoch [408/1000], Loss: 0.0043\n",
      "Epoch [410/1000], Loss: 0.0043\n",
      "Epoch [412/1000], Loss: 0.0043\n",
      "Epoch [414/1000], Loss: 0.0043\n",
      "Epoch [416/1000], Loss: 0.0043\n",
      "Epoch [418/1000], Loss: 0.0043\n",
      "Epoch [420/1000], Loss: 0.0043\n",
      "Epoch [422/1000], Loss: 0.0043\n",
      "Epoch [424/1000], Loss: 0.0043\n",
      "Epoch [426/1000], Loss: 0.0043\n",
      "Epoch [428/1000], Loss: 0.0043\n",
      "Epoch [430/1000], Loss: 0.0043\n",
      "Epoch [432/1000], Loss: 0.0043\n",
      "Epoch [434/1000], Loss: 0.0043\n",
      "Epoch [436/1000], Loss: 0.0043\n",
      "Epoch [404/1000], Loss: 0.0043\n",
      "Epoch [406/1000], Loss: 0.0043\n",
      "Epoch [408/1000], Loss: 0.0043\n",
      "Epoch [410/1000], Loss: 0.0043\n",
      "Epoch [412/1000], Loss: 0.0043\n",
      "Epoch [414/1000], Loss: 0.0043\n",
      "Epoch [416/1000], Loss: 0.0043\n",
      "Epoch [418/1000], Loss: 0.0043\n",
      "Epoch [420/1000], Loss: 0.0043\n",
      "Epoch [422/1000], Loss: 0.0043\n",
      "Epoch [424/1000], Loss: 0.0043\n",
      "Epoch [426/1000], Loss: 0.0043\n",
      "Epoch [428/1000], Loss: 0.0043\n",
      "Epoch [430/1000], Loss: 0.0043\n",
      "Epoch [432/1000], Loss: 0.0043\n",
      "Epoch [434/1000], Loss: 0.0043\n",
      "Epoch [436/1000], Loss: 0.0043\n",
      "Epoch [438/1000], Loss: 0.0043\n",
      "Epoch [440/1000], Loss: 0.0043\n",
      "Epoch [442/1000], Loss: 0.0043\n",
      "Epoch [444/1000], Loss: 0.0043\n",
      "Epoch [446/1000], Loss: 0.0043\n",
      "Epoch [448/1000], Loss: 0.0043\n",
      "Epoch [450/1000], Loss: 0.0043\n",
      "Epoch [452/1000], Loss: 0.0043\n",
      "Epoch [454/1000], Loss: 0.0043\n",
      "Epoch [456/1000], Loss: 0.0043\n",
      "Epoch [458/1000], Loss: 0.0043\n",
      "Epoch [460/1000], Loss: 0.0043\n",
      "Epoch [462/1000], Loss: 0.0043\n",
      "Epoch [464/1000], Loss: 0.0043\n",
      "Epoch [466/1000], Loss: 0.0043\n",
      "Epoch [468/1000], Loss: 0.0043\n",
      "Epoch [438/1000], Loss: 0.0043\n",
      "Epoch [440/1000], Loss: 0.0043\n",
      "Epoch [442/1000], Loss: 0.0043\n",
      "Epoch [444/1000], Loss: 0.0043\n",
      "Epoch [446/1000], Loss: 0.0043\n",
      "Epoch [448/1000], Loss: 0.0043\n",
      "Epoch [450/1000], Loss: 0.0043\n",
      "Epoch [452/1000], Loss: 0.0043\n",
      "Epoch [454/1000], Loss: 0.0043\n",
      "Epoch [456/1000], Loss: 0.0043\n",
      "Epoch [458/1000], Loss: 0.0043\n",
      "Epoch [460/1000], Loss: 0.0043\n",
      "Epoch [462/1000], Loss: 0.0043\n",
      "Epoch [464/1000], Loss: 0.0043\n",
      "Epoch [466/1000], Loss: 0.0043\n",
      "Epoch [468/1000], Loss: 0.0043\n",
      "Epoch [470/1000], Loss: 0.0043\n",
      "Epoch [472/1000], Loss: 0.0043\n",
      "Epoch [474/1000], Loss: 0.0043\n",
      "Epoch [476/1000], Loss: 0.0043\n",
      "Epoch [478/1000], Loss: 0.0043\n",
      "Epoch [480/1000], Loss: 0.0043\n",
      "Epoch [482/1000], Loss: 0.0043\n",
      "Epoch [484/1000], Loss: 0.0043\n",
      "Epoch [486/1000], Loss: 0.0043\n",
      "Epoch [488/1000], Loss: 0.0043\n",
      "Epoch [490/1000], Loss: 0.0043\n",
      "Epoch [492/1000], Loss: 0.0043\n",
      "Epoch [494/1000], Loss: 0.0043\n",
      "Epoch [496/1000], Loss: 0.0043\n",
      "Epoch [498/1000], Loss: 0.0043\n",
      "Epoch [500/1000], Loss: 0.0043\n",
      "Epoch [502/1000], Loss: 0.0043\n",
      "Epoch [504/1000], Loss: 0.0043\n",
      "Epoch [470/1000], Loss: 0.0043\n",
      "Epoch [472/1000], Loss: 0.0043\n",
      "Epoch [474/1000], Loss: 0.0043\n",
      "Epoch [476/1000], Loss: 0.0043\n",
      "Epoch [478/1000], Loss: 0.0043\n",
      "Epoch [480/1000], Loss: 0.0043\n",
      "Epoch [482/1000], Loss: 0.0043\n",
      "Epoch [484/1000], Loss: 0.0043\n",
      "Epoch [486/1000], Loss: 0.0043\n",
      "Epoch [488/1000], Loss: 0.0043\n",
      "Epoch [490/1000], Loss: 0.0043\n",
      "Epoch [492/1000], Loss: 0.0043\n",
      "Epoch [494/1000], Loss: 0.0043\n",
      "Epoch [496/1000], Loss: 0.0043\n",
      "Epoch [498/1000], Loss: 0.0043\n",
      "Epoch [500/1000], Loss: 0.0043\n",
      "Epoch [502/1000], Loss: 0.0043\n",
      "Epoch [504/1000], Loss: 0.0043\n",
      "Epoch [506/1000], Loss: 0.0043\n",
      "Epoch [508/1000], Loss: 0.0043\n",
      "Epoch [510/1000], Loss: 0.0043\n",
      "Epoch [512/1000], Loss: 0.0043\n",
      "Epoch [514/1000], Loss: 0.0043\n",
      "Epoch [516/1000], Loss: 0.0043\n",
      "Epoch [518/1000], Loss: 0.0043\n",
      "Epoch [520/1000], Loss: 0.0043\n",
      "Epoch [522/1000], Loss: 0.0043\n",
      "Epoch [524/1000], Loss: 0.0043\n",
      "Epoch [526/1000], Loss: 0.0043\n",
      "Epoch [528/1000], Loss: 0.0043\n",
      "Epoch [530/1000], Loss: 0.0043\n",
      "Epoch [532/1000], Loss: 0.0043\n",
      "Epoch [534/1000], Loss: 0.0043\n",
      "Epoch [536/1000], Loss: 0.0043\n",
      "Epoch [538/1000], Loss: 0.0043\n",
      "Epoch [540/1000], Loss: 0.0043\n",
      "Epoch [506/1000], Loss: 0.0043\n",
      "Epoch [508/1000], Loss: 0.0043\n",
      "Epoch [510/1000], Loss: 0.0043\n",
      "Epoch [512/1000], Loss: 0.0043\n",
      "Epoch [514/1000], Loss: 0.0043\n",
      "Epoch [516/1000], Loss: 0.0043\n",
      "Epoch [518/1000], Loss: 0.0043\n",
      "Epoch [520/1000], Loss: 0.0043\n",
      "Epoch [522/1000], Loss: 0.0043\n",
      "Epoch [524/1000], Loss: 0.0043\n",
      "Epoch [526/1000], Loss: 0.0043\n",
      "Epoch [528/1000], Loss: 0.0043\n",
      "Epoch [530/1000], Loss: 0.0043\n",
      "Epoch [532/1000], Loss: 0.0043\n",
      "Epoch [534/1000], Loss: 0.0043\n",
      "Epoch [536/1000], Loss: 0.0043\n",
      "Epoch [538/1000], Loss: 0.0043\n",
      "Epoch [540/1000], Loss: 0.0043\n",
      "Epoch [542/1000], Loss: 0.0043\n",
      "Epoch [544/1000], Loss: 0.0043\n",
      "Epoch [546/1000], Loss: 0.0043\n",
      "Epoch [548/1000], Loss: 0.0043\n",
      "Epoch [550/1000], Loss: 0.0043\n",
      "Epoch [552/1000], Loss: 0.0043\n",
      "Epoch [554/1000], Loss: 0.0043\n",
      "Epoch [556/1000], Loss: 0.0043\n",
      "Epoch [558/1000], Loss: 0.0043\n",
      "Epoch [560/1000], Loss: 0.0043\n",
      "Epoch [562/1000], Loss: 0.0043\n",
      "Epoch [564/1000], Loss: 0.0043\n",
      "Epoch [566/1000], Loss: 0.0043\n",
      "Epoch [568/1000], Loss: 0.0043\n",
      "Epoch [570/1000], Loss: 0.0043\n",
      "Epoch [572/1000], Loss: 0.0043\n",
      "Epoch [574/1000], Loss: 0.0043\n",
      "Epoch [542/1000], Loss: 0.0043\n",
      "Epoch [544/1000], Loss: 0.0043\n",
      "Epoch [546/1000], Loss: 0.0043\n",
      "Epoch [548/1000], Loss: 0.0043\n",
      "Epoch [550/1000], Loss: 0.0043\n",
      "Epoch [552/1000], Loss: 0.0043\n",
      "Epoch [554/1000], Loss: 0.0043\n",
      "Epoch [556/1000], Loss: 0.0043\n",
      "Epoch [558/1000], Loss: 0.0043\n",
      "Epoch [560/1000], Loss: 0.0043\n",
      "Epoch [562/1000], Loss: 0.0043\n",
      "Epoch [564/1000], Loss: 0.0043\n",
      "Epoch [566/1000], Loss: 0.0043\n",
      "Epoch [568/1000], Loss: 0.0043\n",
      "Epoch [570/1000], Loss: 0.0043\n",
      "Epoch [572/1000], Loss: 0.0043\n",
      "Epoch [574/1000], Loss: 0.0043\n",
      "Epoch [576/1000], Loss: 0.0043\n",
      "Epoch [578/1000], Loss: 0.0043\n",
      "Epoch [580/1000], Loss: 0.0043\n",
      "Epoch [582/1000], Loss: 0.0043\n",
      "Epoch [584/1000], Loss: 0.0043\n",
      "Epoch [586/1000], Loss: 0.0043\n",
      "Epoch [588/1000], Loss: 0.0043\n",
      "Epoch [590/1000], Loss: 0.0043\n",
      "Epoch [592/1000], Loss: 0.0043\n",
      "Epoch [594/1000], Loss: 0.0043\n",
      "Epoch [596/1000], Loss: 0.0043\n",
      "Epoch [598/1000], Loss: 0.0043\n",
      "Epoch [600/1000], Loss: 0.0043\n",
      "Epoch [602/1000], Loss: 0.0043\n",
      "Epoch [604/1000], Loss: 0.0043\n",
      "Epoch [576/1000], Loss: 0.0043\n",
      "Epoch [578/1000], Loss: 0.0043\n",
      "Epoch [580/1000], Loss: 0.0043\n",
      "Epoch [582/1000], Loss: 0.0043\n",
      "Epoch [584/1000], Loss: 0.0043\n",
      "Epoch [586/1000], Loss: 0.0043\n",
      "Epoch [588/1000], Loss: 0.0043\n",
      "Epoch [590/1000], Loss: 0.0043\n",
      "Epoch [592/1000], Loss: 0.0043\n",
      "Epoch [594/1000], Loss: 0.0043\n",
      "Epoch [596/1000], Loss: 0.0043\n",
      "Epoch [598/1000], Loss: 0.0043\n",
      "Epoch [600/1000], Loss: 0.0043\n",
      "Epoch [602/1000], Loss: 0.0043\n",
      "Epoch [604/1000], Loss: 0.0043\n",
      "Epoch [606/1000], Loss: 0.0043\n",
      "Epoch [608/1000], Loss: 0.0043\n",
      "Epoch [610/1000], Loss: 0.0043\n",
      "Epoch [612/1000], Loss: 0.0043\n",
      "Epoch [614/1000], Loss: 0.0043\n",
      "Epoch [616/1000], Loss: 0.0043\n",
      "Epoch [618/1000], Loss: 0.0043\n",
      "Epoch [620/1000], Loss: 0.0043\n",
      "Epoch [622/1000], Loss: 0.0043\n",
      "Epoch [624/1000], Loss: 0.0043\n",
      "Epoch [626/1000], Loss: 0.0043\n",
      "Epoch [628/1000], Loss: 0.0043\n",
      "Epoch [630/1000], Loss: 0.0043\n",
      "Epoch [632/1000], Loss: 0.0043\n",
      "Epoch [634/1000], Loss: 0.0043\n",
      "Epoch [636/1000], Loss: 0.0043\n",
      "Epoch [638/1000], Loss: 0.0043\n",
      "Epoch [606/1000], Loss: 0.0043\n",
      "Epoch [608/1000], Loss: 0.0043\n",
      "Epoch [610/1000], Loss: 0.0043\n",
      "Epoch [612/1000], Loss: 0.0043\n",
      "Epoch [614/1000], Loss: 0.0043\n",
      "Epoch [616/1000], Loss: 0.0043\n",
      "Epoch [618/1000], Loss: 0.0043\n",
      "Epoch [620/1000], Loss: 0.0043\n",
      "Epoch [622/1000], Loss: 0.0043\n",
      "Epoch [624/1000], Loss: 0.0043\n",
      "Epoch [626/1000], Loss: 0.0043\n",
      "Epoch [628/1000], Loss: 0.0043\n",
      "Epoch [630/1000], Loss: 0.0043\n",
      "Epoch [632/1000], Loss: 0.0043\n",
      "Epoch [634/1000], Loss: 0.0043\n",
      "Epoch [636/1000], Loss: 0.0043\n",
      "Epoch [638/1000], Loss: 0.0043\n",
      "Epoch [640/1000], Loss: 0.0043\n",
      "Epoch [642/1000], Loss: 0.0043\n",
      "Epoch [644/1000], Loss: 0.0043\n",
      "Epoch [646/1000], Loss: 0.0043\n",
      "Epoch [648/1000], Loss: 0.0043\n",
      "Epoch [650/1000], Loss: 0.0043\n",
      "Epoch [652/1000], Loss: 0.0043\n",
      "Epoch [654/1000], Loss: 0.0043\n",
      "Epoch [656/1000], Loss: 0.0043\n",
      "Epoch [658/1000], Loss: 0.0043\n",
      "Epoch [660/1000], Loss: 0.0043\n",
      "Epoch [662/1000], Loss: 0.0043\n",
      "Epoch [664/1000], Loss: 0.0043\n",
      "Epoch [666/1000], Loss: 0.0043\n",
      "Epoch [668/1000], Loss: 0.0043\n",
      "Epoch [670/1000], Loss: 0.0043\n",
      "Epoch [672/1000], Loss: 0.0043\n",
      "Epoch [640/1000], Loss: 0.0043\n",
      "Epoch [642/1000], Loss: 0.0043\n",
      "Epoch [644/1000], Loss: 0.0043\n",
      "Epoch [646/1000], Loss: 0.0043\n",
      "Epoch [648/1000], Loss: 0.0043\n",
      "Epoch [650/1000], Loss: 0.0043\n",
      "Epoch [652/1000], Loss: 0.0043\n",
      "Epoch [654/1000], Loss: 0.0043\n",
      "Epoch [656/1000], Loss: 0.0043\n",
      "Epoch [658/1000], Loss: 0.0043\n",
      "Epoch [660/1000], Loss: 0.0043\n",
      "Epoch [662/1000], Loss: 0.0043\n",
      "Epoch [664/1000], Loss: 0.0043\n",
      "Epoch [666/1000], Loss: 0.0043\n",
      "Epoch [668/1000], Loss: 0.0043\n",
      "Epoch [670/1000], Loss: 0.0043\n",
      "Epoch [672/1000], Loss: 0.0043\n",
      "Epoch [674/1000], Loss: 0.0043\n",
      "Epoch [676/1000], Loss: 0.0043\n",
      "Epoch [678/1000], Loss: 0.0043\n",
      "Epoch [680/1000], Loss: 0.0043\n",
      "Epoch [682/1000], Loss: 0.0043\n",
      "Epoch [684/1000], Loss: 0.0043\n",
      "Epoch [686/1000], Loss: 0.0043\n",
      "Epoch [688/1000], Loss: 0.0043\n",
      "Epoch [690/1000], Loss: 0.0043\n",
      "Epoch [692/1000], Loss: 0.0043\n",
      "Epoch [694/1000], Loss: 0.0043\n",
      "Epoch [696/1000], Loss: 0.0043\n",
      "Epoch [698/1000], Loss: 0.0043\n",
      "Epoch [700/1000], Loss: 0.0043\n",
      "Epoch [702/1000], Loss: 0.0043\n",
      "Epoch [704/1000], Loss: 0.0043\n",
      "Epoch [674/1000], Loss: 0.0043\n",
      "Epoch [676/1000], Loss: 0.0043\n",
      "Epoch [678/1000], Loss: 0.0043\n",
      "Epoch [680/1000], Loss: 0.0043\n",
      "Epoch [682/1000], Loss: 0.0043\n",
      "Epoch [684/1000], Loss: 0.0043\n",
      "Epoch [686/1000], Loss: 0.0043\n",
      "Epoch [688/1000], Loss: 0.0043\n",
      "Epoch [690/1000], Loss: 0.0043\n",
      "Epoch [692/1000], Loss: 0.0043\n",
      "Epoch [694/1000], Loss: 0.0043\n",
      "Epoch [696/1000], Loss: 0.0043\n",
      "Epoch [698/1000], Loss: 0.0043\n",
      "Epoch [700/1000], Loss: 0.0043\n",
      "Epoch [702/1000], Loss: 0.0043\n",
      "Epoch [704/1000], Loss: 0.0043\n",
      "Epoch [706/1000], Loss: 0.0043\n",
      "Epoch [708/1000], Loss: 0.0043\n",
      "Epoch [710/1000], Loss: 0.0043\n",
      "Epoch [712/1000], Loss: 0.0043\n",
      "Epoch [714/1000], Loss: 0.0043\n",
      "Epoch [716/1000], Loss: 0.0043\n",
      "Epoch [718/1000], Loss: 0.0043\n",
      "Epoch [720/1000], Loss: 0.0043\n",
      "Epoch [722/1000], Loss: 0.0043\n",
      "Epoch [724/1000], Loss: 0.0043\n",
      "Epoch [726/1000], Loss: 0.0043\n",
      "Epoch [728/1000], Loss: 0.0043\n",
      "Epoch [730/1000], Loss: 0.0043\n",
      "Epoch [732/1000], Loss: 0.0043\n",
      "Epoch [734/1000], Loss: 0.0043\n",
      "Epoch [736/1000], Loss: 0.0043\n",
      "Epoch [738/1000], Loss: 0.0043\n",
      "Epoch [706/1000], Loss: 0.0043\n",
      "Epoch [708/1000], Loss: 0.0043\n",
      "Epoch [710/1000], Loss: 0.0043\n",
      "Epoch [712/1000], Loss: 0.0043\n",
      "Epoch [714/1000], Loss: 0.0043\n",
      "Epoch [716/1000], Loss: 0.0043\n",
      "Epoch [718/1000], Loss: 0.0043\n",
      "Epoch [720/1000], Loss: 0.0043\n",
      "Epoch [722/1000], Loss: 0.0043\n",
      "Epoch [724/1000], Loss: 0.0043\n",
      "Epoch [726/1000], Loss: 0.0043\n",
      "Epoch [728/1000], Loss: 0.0043\n",
      "Epoch [730/1000], Loss: 0.0043\n",
      "Epoch [732/1000], Loss: 0.0043\n",
      "Epoch [734/1000], Loss: 0.0043\n",
      "Epoch [736/1000], Loss: 0.0043\n",
      "Epoch [738/1000], Loss: 0.0043\n",
      "Epoch [740/1000], Loss: 0.0043\n",
      "Epoch [742/1000], Loss: 0.0043\n",
      "Epoch [744/1000], Loss: 0.0043\n",
      "Epoch [746/1000], Loss: 0.0043\n",
      "Epoch [748/1000], Loss: 0.0043\n",
      "Epoch [750/1000], Loss: 0.0043\n",
      "Epoch [752/1000], Loss: 0.0043\n",
      "Epoch [754/1000], Loss: 0.0043\n",
      "Epoch [756/1000], Loss: 0.0043\n",
      "Epoch [758/1000], Loss: 0.0043\n",
      "Epoch [760/1000], Loss: 0.0043\n",
      "Epoch [762/1000], Loss: 0.0043\n",
      "Epoch [764/1000], Loss: 0.0043\n",
      "Epoch [766/1000], Loss: 0.0043\n",
      "Epoch [768/1000], Loss: 0.0043\n",
      "Epoch [770/1000], Loss: 0.0043\n",
      "Epoch [740/1000], Loss: 0.0043\n",
      "Epoch [742/1000], Loss: 0.0043\n",
      "Epoch [744/1000], Loss: 0.0043\n",
      "Epoch [746/1000], Loss: 0.0043\n",
      "Epoch [748/1000], Loss: 0.0043\n",
      "Epoch [750/1000], Loss: 0.0043\n",
      "Epoch [752/1000], Loss: 0.0043\n",
      "Epoch [754/1000], Loss: 0.0043\n",
      "Epoch [756/1000], Loss: 0.0043\n",
      "Epoch [758/1000], Loss: 0.0043\n",
      "Epoch [760/1000], Loss: 0.0043\n",
      "Epoch [762/1000], Loss: 0.0043\n",
      "Epoch [764/1000], Loss: 0.0043\n",
      "Epoch [766/1000], Loss: 0.0043\n",
      "Epoch [768/1000], Loss: 0.0043\n",
      "Epoch [770/1000], Loss: 0.0043\n",
      "Epoch [772/1000], Loss: 0.0043\n",
      "Epoch [774/1000], Loss: 0.0043\n",
      "Epoch [776/1000], Loss: 0.0043\n",
      "Epoch [778/1000], Loss: 0.0043\n",
      "Epoch [780/1000], Loss: 0.0043\n",
      "Epoch [782/1000], Loss: 0.0043\n",
      "Epoch [784/1000], Loss: 0.0043\n",
      "Epoch [786/1000], Loss: 0.0043\n",
      "Epoch [788/1000], Loss: 0.0043\n",
      "Epoch [790/1000], Loss: 0.0043\n",
      "Epoch [792/1000], Loss: 0.0043\n",
      "Epoch [794/1000], Loss: 0.0043\n",
      "Epoch [796/1000], Loss: 0.0043\n",
      "Epoch [798/1000], Loss: 0.0043\n",
      "Epoch [800/1000], Loss: 0.0043\n",
      "Epoch [802/1000], Loss: 0.0043\n",
      "Epoch [804/1000], Loss: 0.0043\n",
      "Epoch [806/1000], Loss: 0.0043\n",
      "Epoch [772/1000], Loss: 0.0043\n",
      "Epoch [774/1000], Loss: 0.0043\n",
      "Epoch [776/1000], Loss: 0.0043\n",
      "Epoch [778/1000], Loss: 0.0043\n",
      "Epoch [780/1000], Loss: 0.0043\n",
      "Epoch [782/1000], Loss: 0.0043\n",
      "Epoch [784/1000], Loss: 0.0043\n",
      "Epoch [786/1000], Loss: 0.0043\n",
      "Epoch [788/1000], Loss: 0.0043\n",
      "Epoch [790/1000], Loss: 0.0043\n",
      "Epoch [792/1000], Loss: 0.0043\n",
      "Epoch [794/1000], Loss: 0.0043\n",
      "Epoch [796/1000], Loss: 0.0043\n",
      "Epoch [798/1000], Loss: 0.0043\n",
      "Epoch [800/1000], Loss: 0.0043\n",
      "Epoch [802/1000], Loss: 0.0043\n",
      "Epoch [804/1000], Loss: 0.0043\n",
      "Epoch [806/1000], Loss: 0.0043\n",
      "Epoch [808/1000], Loss: 0.0043\n",
      "Epoch [810/1000], Loss: 0.0043\n",
      "Epoch [812/1000], Loss: 0.0043\n",
      "Epoch [814/1000], Loss: 0.0043\n",
      "Epoch [816/1000], Loss: 0.0043\n",
      "Epoch [818/1000], Loss: 0.0043\n",
      "Epoch [820/1000], Loss: 0.0043\n",
      "Epoch [822/1000], Loss: 0.0043\n",
      "Epoch [824/1000], Loss: 0.0043\n",
      "Epoch [826/1000], Loss: 0.0043\n",
      "Epoch [828/1000], Loss: 0.0043\n",
      "Epoch [830/1000], Loss: 0.0043\n",
      "Epoch [832/1000], Loss: 0.0043\n",
      "Epoch [834/1000], Loss: 0.0043\n",
      "Epoch [836/1000], Loss: 0.0043\n",
      "Epoch [838/1000], Loss: 0.0043\n",
      "Epoch [840/1000], Loss: 0.0043\n",
      "Epoch [842/1000], Loss: 0.0043\n",
      "Epoch [844/1000], Loss: 0.0043\n",
      "Epoch [808/1000], Loss: 0.0043\n",
      "Epoch [810/1000], Loss: 0.0043\n",
      "Epoch [812/1000], Loss: 0.0043\n",
      "Epoch [814/1000], Loss: 0.0043\n",
      "Epoch [816/1000], Loss: 0.0043\n",
      "Epoch [818/1000], Loss: 0.0043\n",
      "Epoch [820/1000], Loss: 0.0043\n",
      "Epoch [822/1000], Loss: 0.0043\n",
      "Epoch [824/1000], Loss: 0.0043\n",
      "Epoch [826/1000], Loss: 0.0043\n",
      "Epoch [828/1000], Loss: 0.0043\n",
      "Epoch [830/1000], Loss: 0.0043\n",
      "Epoch [832/1000], Loss: 0.0043\n",
      "Epoch [834/1000], Loss: 0.0043\n",
      "Epoch [836/1000], Loss: 0.0043\n",
      "Epoch [838/1000], Loss: 0.0043\n",
      "Epoch [840/1000], Loss: 0.0043\n",
      "Epoch [842/1000], Loss: 0.0043\n",
      "Epoch [844/1000], Loss: 0.0043\n",
      "Epoch [846/1000], Loss: 0.0043\n",
      "Epoch [848/1000], Loss: 0.0043\n",
      "Epoch [850/1000], Loss: 0.0043\n",
      "Epoch [852/1000], Loss: 0.0043\n",
      "Epoch [854/1000], Loss: 0.0043\n",
      "Epoch [856/1000], Loss: 0.0043\n",
      "Epoch [858/1000], Loss: 0.0043\n",
      "Epoch [860/1000], Loss: 0.0043\n",
      "Epoch [862/1000], Loss: 0.0043\n",
      "Epoch [864/1000], Loss: 0.0043\n",
      "Epoch [866/1000], Loss: 0.0043\n",
      "Epoch [868/1000], Loss: 0.0043\n",
      "Epoch [870/1000], Loss: 0.0043\n",
      "Epoch [872/1000], Loss: 0.0043\n",
      "Epoch [874/1000], Loss: 0.0043\n",
      "Epoch [876/1000], Loss: 0.0043\n",
      "Epoch [878/1000], Loss: 0.0043\n",
      "Epoch [846/1000], Loss: 0.0043\n",
      "Epoch [848/1000], Loss: 0.0043\n",
      "Epoch [850/1000], Loss: 0.0043\n",
      "Epoch [852/1000], Loss: 0.0043\n",
      "Epoch [854/1000], Loss: 0.0043\n",
      "Epoch [856/1000], Loss: 0.0043\n",
      "Epoch [858/1000], Loss: 0.0043\n",
      "Epoch [860/1000], Loss: 0.0043\n",
      "Epoch [862/1000], Loss: 0.0043\n",
      "Epoch [864/1000], Loss: 0.0043\n",
      "Epoch [866/1000], Loss: 0.0043\n",
      "Epoch [868/1000], Loss: 0.0043\n",
      "Epoch [870/1000], Loss: 0.0043\n",
      "Epoch [872/1000], Loss: 0.0043\n",
      "Epoch [874/1000], Loss: 0.0043\n",
      "Epoch [876/1000], Loss: 0.0043\n",
      "Epoch [878/1000], Loss: 0.0043\n",
      "Epoch [880/1000], Loss: 0.0043\n",
      "Epoch [882/1000], Loss: 0.0043\n",
      "Epoch [884/1000], Loss: 0.0043\n",
      "Epoch [886/1000], Loss: 0.0043\n",
      "Epoch [888/1000], Loss: 0.0043\n",
      "Epoch [890/1000], Loss: 0.0043\n",
      "Epoch [892/1000], Loss: 0.0043\n",
      "Epoch [894/1000], Loss: 0.0043\n",
      "Epoch [896/1000], Loss: 0.0043\n",
      "Epoch [898/1000], Loss: 0.0043\n",
      "Epoch [900/1000], Loss: 0.0043\n",
      "Epoch [902/1000], Loss: 0.0043\n",
      "Epoch [904/1000], Loss: 0.0043\n",
      "Epoch [906/1000], Loss: 0.0043\n",
      "Epoch [908/1000], Loss: 0.0043\n",
      "Epoch [910/1000], Loss: 0.0043\n",
      "Epoch [912/1000], Loss: 0.0043\n",
      "Epoch [914/1000], Loss: 0.0043\n",
      "Epoch [880/1000], Loss: 0.0043\n",
      "Epoch [882/1000], Loss: 0.0043\n",
      "Epoch [884/1000], Loss: 0.0043\n",
      "Epoch [886/1000], Loss: 0.0043\n",
      "Epoch [888/1000], Loss: 0.0043\n",
      "Epoch [890/1000], Loss: 0.0043\n",
      "Epoch [892/1000], Loss: 0.0043\n",
      "Epoch [894/1000], Loss: 0.0043\n",
      "Epoch [896/1000], Loss: 0.0043\n",
      "Epoch [898/1000], Loss: 0.0043\n",
      "Epoch [900/1000], Loss: 0.0043\n",
      "Epoch [902/1000], Loss: 0.0043\n",
      "Epoch [904/1000], Loss: 0.0043\n",
      "Epoch [906/1000], Loss: 0.0043\n",
      "Epoch [908/1000], Loss: 0.0043\n",
      "Epoch [910/1000], Loss: 0.0043\n",
      "Epoch [912/1000], Loss: 0.0043\n",
      "Epoch [914/1000], Loss: 0.0043\n",
      "Epoch [916/1000], Loss: 0.0043\n",
      "Epoch [918/1000], Loss: 0.0043\n",
      "Epoch [920/1000], Loss: 0.0043\n",
      "Epoch [922/1000], Loss: 0.0043\n",
      "Epoch [924/1000], Loss: 0.0043\n",
      "Epoch [926/1000], Loss: 0.0043\n",
      "Epoch [928/1000], Loss: 0.0043\n",
      "Epoch [930/1000], Loss: 0.0043\n",
      "Epoch [932/1000], Loss: 0.0043\n",
      "Epoch [934/1000], Loss: 0.0043\n",
      "Epoch [936/1000], Loss: 0.0043\n",
      "Epoch [938/1000], Loss: 0.0043\n",
      "Epoch [940/1000], Loss: 0.0043\n",
      "Epoch [942/1000], Loss: 0.0043\n",
      "Epoch [944/1000], Loss: 0.0043\n",
      "Epoch [946/1000], Loss: 0.0043\n",
      "Epoch [948/1000], Loss: 0.0043\n",
      "Epoch [916/1000], Loss: 0.0043\n",
      "Epoch [918/1000], Loss: 0.0043\n",
      "Epoch [920/1000], Loss: 0.0043\n",
      "Epoch [922/1000], Loss: 0.0043\n",
      "Epoch [924/1000], Loss: 0.0043\n",
      "Epoch [926/1000], Loss: 0.0043\n",
      "Epoch [928/1000], Loss: 0.0043\n",
      "Epoch [930/1000], Loss: 0.0043\n",
      "Epoch [932/1000], Loss: 0.0043\n",
      "Epoch [934/1000], Loss: 0.0043\n",
      "Epoch [936/1000], Loss: 0.0043\n",
      "Epoch [938/1000], Loss: 0.0043\n",
      "Epoch [940/1000], Loss: 0.0043\n",
      "Epoch [942/1000], Loss: 0.0043\n",
      "Epoch [944/1000], Loss: 0.0043\n",
      "Epoch [946/1000], Loss: 0.0043\n",
      "Epoch [948/1000], Loss: 0.0043\n",
      "Epoch [950/1000], Loss: 0.0043\n",
      "Epoch [952/1000], Loss: 0.0043\n",
      "Epoch [954/1000], Loss: 0.0043\n",
      "Epoch [956/1000], Loss: 0.0043\n",
      "Epoch [958/1000], Loss: 0.0043\n",
      "Epoch [960/1000], Loss: 0.0043\n",
      "Epoch [962/1000], Loss: 0.0043\n",
      "Epoch [964/1000], Loss: 0.0043\n",
      "Epoch [966/1000], Loss: 0.0043\n",
      "Epoch [968/1000], Loss: 0.0043\n",
      "Epoch [970/1000], Loss: 0.0043\n",
      "Epoch [972/1000], Loss: 0.0043\n",
      "Epoch [974/1000], Loss: 0.0043\n",
      "Epoch [976/1000], Loss: 0.0043\n",
      "Epoch [978/1000], Loss: 0.0043\n",
      "Epoch [980/1000], Loss: 0.0043\n",
      "Epoch [982/1000], Loss: 0.0043\n",
      "Epoch [984/1000], Loss: 0.0043\n",
      "Epoch [950/1000], Loss: 0.0043\n",
      "Epoch [952/1000], Loss: 0.0043\n",
      "Epoch [954/1000], Loss: 0.0043\n",
      "Epoch [956/1000], Loss: 0.0043\n",
      "Epoch [958/1000], Loss: 0.0043\n",
      "Epoch [960/1000], Loss: 0.0043\n",
      "Epoch [962/1000], Loss: 0.0043\n",
      "Epoch [964/1000], Loss: 0.0043\n",
      "Epoch [966/1000], Loss: 0.0043\n",
      "Epoch [968/1000], Loss: 0.0043\n",
      "Epoch [970/1000], Loss: 0.0043\n",
      "Epoch [972/1000], Loss: 0.0043\n",
      "Epoch [974/1000], Loss: 0.0043\n",
      "Epoch [976/1000], Loss: 0.0043\n",
      "Epoch [978/1000], Loss: 0.0043\n",
      "Epoch [980/1000], Loss: 0.0043\n",
      "Epoch [982/1000], Loss: 0.0043\n",
      "Epoch [984/1000], Loss: 0.0043\n",
      "Epoch [986/1000], Loss: 0.0043\n",
      "Epoch [988/1000], Loss: 0.0043\n",
      "Epoch [990/1000], Loss: 0.0043\n",
      "Epoch [992/1000], Loss: 0.0043\n",
      "Epoch [994/1000], Loss: 0.0043\n",
      "Epoch [996/1000], Loss: 0.0043\n",
      "Epoch [998/1000], Loss: 0.0043\n",
      "Epoch [1000/1000], Loss: 0.0043\n",
      "Epoch [986/1000], Loss: 0.0043\n",
      "Epoch [988/1000], Loss: 0.0043\n",
      "Epoch [990/1000], Loss: 0.0043\n",
      "Epoch [992/1000], Loss: 0.0043\n",
      "Epoch [994/1000], Loss: 0.0043\n",
      "Epoch [996/1000], Loss: 0.0043\n",
      "Epoch [998/1000], Loss: 0.0043\n",
      "Epoch [1000/1000], Loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad() # before we compute new gradients, we must clear old gradients\n",
    "\n",
    "    outputs = model(X_train) # it does: X_train → fc1 → relu → fc2 → relu → output layer\n",
    "    loss = criteration(outputs, y_train)\n",
    "\n",
    "    loss.backward() # pytorch computes the gradient of loss with reepect to every weight in the network\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5897f",
   "metadata": {},
   "source": [
    "# Step 8 - Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45359577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.39024388790130615\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "\n",
    "accuracy = (predicted == y_test).float().mean()\n",
    "print(\"Accuracy: \", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de777e",
   "metadata": {},
   "source": [
    "# Step 9 - Predict on new sysptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "eae6c877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pneumonia\n"
     ]
    }
   ],
   "source": [
    "def predict(symptoms_text):\n",
    "    model.eval()\n",
    "    x = vectorizer.transform([symptoms_text]).toarray()\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(x)\n",
    "        _, pred = torch.max(output, 1)\n",
    "        \n",
    "    disease = encoder.inverse_transform(pred.numpy())[0]\n",
    "    return disease\n",
    "\n",
    "print(predict(\"fever and dry cough\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
